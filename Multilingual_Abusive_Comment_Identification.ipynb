{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Importing Libraries & Languages that are required</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from indicnlp import common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The path to the local git repo for Indic NLP library\n",
    "INDIC_NLP_LIB_HOME=r\"/Users/sudheera/workspace/python/CS584/indic_nlp_library\"\n",
    "\n",
    "# The path to the local git repo for Indic NLP Resources\n",
    "INDIC_NLP_RESOURCES=r\"/Users/sudheera/workspace/python/CS584/indic_nlp_resources\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add library to Python path\n",
    "sys.path.append(r'{}\\src'.format(INDIC_NLP_LIB_HOME))\n",
    "\n",
    "# Set environment variable for resources folder\n",
    "common.set_resources_path(INDIC_NLP_RESOURCES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inltk.inltk import setup\n",
    "setup(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza\n",
    "stanza.download('en')\n",
    "stanza_nlp = stanza.Pipeline('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Importing Data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "train_data = pd.read_csv(\"/Users/sudheera/workspace/python/CS584/Multilingual_Abusive_Comment_Identification/train_set.csv\", delimiter=\",\")\n",
    "test_data = pd.read_csv(\"/Users/sudheera/workspace/python/CS584/Multilingual_Abusive_Comment_Identification/test_set.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Exploring Data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.52987\n",
       "1    0.47013\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"label\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hindi         0.461896\n",
       "Telugu        0.145873\n",
       "Marathi       0.108330\n",
       "Tamil         0.104500\n",
       "Malayalam     0.061598\n",
       "Bengali       0.034336\n",
       "Kannada       0.020966\n",
       "Odia          0.016501\n",
       "Gujarati      0.013274\n",
       "Haryanvi      0.013250\n",
       "Bhojpuri      0.008727\n",
       "Rajasthani    0.006568\n",
       "Assamese      0.004180\n",
       "Name: language, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"language\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isna().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.isna().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(665042, 9)\n",
      "(74253, 8)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>post_index</th>\n",
       "      <th>commentText</th>\n",
       "      <th>report_count_comment</th>\n",
       "      <th>report_count_post</th>\n",
       "      <th>like_count_comment</th>\n",
       "      <th>like_count_post</th>\n",
       "      <th>label</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hindi</td>\n",
       "      <td>238566</td>\n",
       "      <td>‡§∂‡§æ‡§Ø‡§¶ ‡§Ø‡•ã‡§ó‡•Ä ‡§ú‡•Ä ‡§π‡•à</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hindi</td>\n",
       "      <td>7009</td>\n",
       "      <td>Tingri h to putri tu.. .</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hindi</td>\n",
       "      <td>404648</td>\n",
       "      <td>Saale Tu kon sa pagal Nahi h . Teri comment pa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hindi</td>\n",
       "      <td>5057</td>\n",
       "      <td>girl üòòüòò aaj ke baad msg ki to maar daluggi</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hindi</td>\n",
       "      <td>107146</td>\n",
       "      <td>Free fire pubg ka baap ha kutta sala kamina</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665037</th>\n",
       "      <td>Hindi</td>\n",
       "      <td>372573</td>\n",
       "      <td>Yr bhai ye launda jahar h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>530</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665038</th>\n",
       "      <td>Hindi</td>\n",
       "      <td>271190</td>\n",
       "      <td>‚É¢‚ò†Ô∏éÔ∏éü¶ÖüÖ°Ô∏é ‚É¢üÖ¥Ô∏é ‚É¢üÖóÔ∏é‚É¢ üÖ∞Ô∏éüÖΩÔ∏é‚ëÖ‚Éùüíú‚úîÔ∏é koshish kr lo dodne...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665039</th>\n",
       "      <td>Hindi</td>\n",
       "      <td>356484</td>\n",
       "      <td>‡§¨‡•á‡§∞‡•Ä‡§®‡§æ‡§à‡§∏ ‡§™‡§ø‡§ï ‡§ú‡•Ä üáÆüá≥ *üôè üôè</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665040</th>\n",
       "      <td>Hindi</td>\n",
       "      <td>356897</td>\n",
       "      <td>Amit mar do sale ko</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665041</th>\n",
       "      <td>Hindi</td>\n",
       "      <td>100617</td>\n",
       "      <td>Mardar kyuki do galas h</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>665042 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       language  post_index  \\\n",
       "0         Hindi      238566   \n",
       "1         Hindi        7009   \n",
       "2         Hindi      404648   \n",
       "3         Hindi        5057   \n",
       "4         Hindi      107146   \n",
       "...         ...         ...   \n",
       "665037    Hindi      372573   \n",
       "665038    Hindi      271190   \n",
       "665039    Hindi      356484   \n",
       "665040    Hindi      356897   \n",
       "665041    Hindi      100617   \n",
       "\n",
       "                                              commentText  \\\n",
       "0                                         ‡§∂‡§æ‡§Ø‡§¶ ‡§Ø‡•ã‡§ó‡•Ä ‡§ú‡•Ä ‡§π‡•à   \n",
       "1                                Tingri h to putri tu.. .   \n",
       "2       Saale Tu kon sa pagal Nahi h . Teri comment pa...   \n",
       "3              girl üòòüòò aaj ke baad msg ki to maar daluggi   \n",
       "4             Free fire pubg ka baap ha kutta sala kamina   \n",
       "...                                                   ...   \n",
       "665037                       Yr bhai ye launda jahar h...   \n",
       "665038  ‚É¢‚ò†Ô∏éÔ∏éü¶ÖüÖ°Ô∏é ‚É¢üÖ¥Ô∏é ‚É¢üÖóÔ∏é‚É¢ üÖ∞Ô∏éüÖΩÔ∏é‚ëÖ‚Éùüíú‚úîÔ∏é koshish kr lo dodne...   \n",
       "665039                            ‡§¨‡•á‡§∞‡•Ä‡§®‡§æ‡§à‡§∏ ‡§™‡§ø‡§ï ‡§ú‡•Ä üáÆüá≥ *üôè üôè   \n",
       "665040                                Amit mar do sale ko   \n",
       "665041                            Mardar kyuki do galas h   \n",
       "\n",
       "        report_count_comment  report_count_post  like_count_comment  \\\n",
       "0                          0                  0                   1   \n",
       "1                          0                  0                   0   \n",
       "2                          0                  0                   0   \n",
       "3                          0                  0                   0   \n",
       "4                          0                  0                   0   \n",
       "...                      ...                ...                 ...   \n",
       "665037                     0                  0                   1   \n",
       "665038                     0                  0                   0   \n",
       "665039                     0                  0                   0   \n",
       "665040                     0                  0                   0   \n",
       "665041                     0                  0                   0   \n",
       "\n",
       "        like_count_post  label  val  \n",
       "0                     1      0    0  \n",
       "1                     0      0    0  \n",
       "2                     0      1    0  \n",
       "3                     0      0    0  \n",
       "4                     0      1    0  \n",
       "...                 ...    ...  ...  \n",
       "665037              530      0    0  \n",
       "665038                0      0    0  \n",
       "665039                0      0    0  \n",
       "665040                0      0    0  \n",
       "665041                0      1    0  \n",
       "\n",
       "[665042 rows x 9 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>language</th>\n",
       "      <th>post_index</th>\n",
       "      <th>commentText</th>\n",
       "      <th>report_count_comment</th>\n",
       "      <th>report_count_post</th>\n",
       "      <th>like_count_comment</th>\n",
       "      <th>like_count_post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Bengali</td>\n",
       "      <td>182442</td>\n",
       "      <td>Bichna theke agun berochhe re tar modhhyeu ami...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>406921</td>\n",
       "      <td>JYOTIüíè chut ka pani</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>233255</td>\n",
       "      <td>Kuth tik n h</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Telugu</td>\n",
       "      <td>219308</td>\n",
       "      <td>Ekkada ap valaki kallu guddi ah?üò†sarigga chuda...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>269812</td>\n",
       "      <td>pagal khi ke gadhe me dha aata h bachho se kuc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74248</th>\n",
       "      <td>74250</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>358105</td>\n",
       "      <td>Bhabhi ji banne se pahle sali ka kapda Palo bh...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74249</th>\n",
       "      <td>74251</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>275919</td>\n",
       "      <td>Nice gannd  dogi kya</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74250</th>\n",
       "      <td>74252</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>33762</td>\n",
       "      <td>Tumhare boobs ke Dam per pahchan Hai Tumhara</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74251</th>\n",
       "      <td>74253</td>\n",
       "      <td>Marathi</td>\n",
       "      <td>381085</td>\n",
       "      <td>Tu ‡§â‡§ó‡§æ‡§ö ‡§â‡§°‡§§‡§æ ‡§§‡§ø‡§∞ ‡§ò‡•á‡§§ aahes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74252</th>\n",
       "      <td>74254</td>\n",
       "      <td>Marathi</td>\n",
       "      <td>382840</td>\n",
       "      <td>Tyla avdla mhanun tyane takla ytumala kay kara...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74253 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id language  post_index  \\\n",
       "0          2  Bengali      182442   \n",
       "1          3    Hindi      406921   \n",
       "2          4    Hindi      233255   \n",
       "3          5   Telugu      219308   \n",
       "4          6    Hindi      269812   \n",
       "...      ...      ...         ...   \n",
       "74248  74250    Hindi      358105   \n",
       "74249  74251    Hindi      275919   \n",
       "74250  74252    Hindi       33762   \n",
       "74251  74253  Marathi      381085   \n",
       "74252  74254  Marathi      382840   \n",
       "\n",
       "                                             commentText  \\\n",
       "0      Bichna theke agun berochhe re tar modhhyeu ami...   \n",
       "1                                    JYOTIüíè chut ka pani   \n",
       "2                                           Kuth tik n h   \n",
       "3      Ekkada ap valaki kallu guddi ah?üò†sarigga chuda...   \n",
       "4      pagal khi ke gadhe me dha aata h bachho se kuc...   \n",
       "...                                                  ...   \n",
       "74248  Bhabhi ji banne se pahle sali ka kapda Palo bh...   \n",
       "74249                               Nice gannd  dogi kya   \n",
       "74250       Tumhare boobs ke Dam per pahchan Hai Tumhara   \n",
       "74251                         Tu ‡§â‡§ó‡§æ‡§ö ‡§â‡§°‡§§‡§æ ‡§§‡§ø‡§∞ ‡§ò‡•á‡§§ aahes   \n",
       "74252  Tyla avdla mhanun tyane takla ytumala kay kara...   \n",
       "\n",
       "       report_count_comment  report_count_post  like_count_comment  \\\n",
       "0                         0                  0                   0   \n",
       "1                         0                  0                   0   \n",
       "2                         0                  0                   0   \n",
       "3                         0                  0                   0   \n",
       "4                         0                  0                   0   \n",
       "...                     ...                ...                 ...   \n",
       "74248                     0                  0                   0   \n",
       "74249                     0                  0                   0   \n",
       "74250                     0                  0                   0   \n",
       "74251                     0                  0                   0   \n",
       "74252                     0                  0                   0   \n",
       "\n",
       "       like_count_post  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  \n",
       "...                ...  \n",
       "74248                0  \n",
       "74249                0  \n",
       "74250                0  \n",
       "74251                0  \n",
       "74252                0  \n",
       "\n",
       "[74253 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Pre-Processing</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import unicodedata\n",
    "from bs4 import BeautifulSoup\n",
    "import emoji\n",
    "\n",
    "def pre_process(string):\n",
    "    # 1. Remove HTML tags\n",
    "    textOnly = BeautifulSoup(string, features=\"html.parser\").get_text() \n",
    "\n",
    "\n",
    "    # 2. Remove Email IDs, URLs and numbers\n",
    "    noEmail = re.sub(r'([\\w\\.-]+@[\\w\\.-]+\\.\\w+)','',textOnly)\n",
    "    \n",
    "    noUrl = re.sub(r'(?i)\\b((?:[a-z][\\w-]+:(?:/{1,3}|[a-z0-9%])|www\\d{0,3}[.]| \\\n",
    "        [a-z0-9.\\-]+[.][a-z]{2,4}/|[a-z0-9.\\-]+[.][a-z])(?:[^\\s()<>]+|\\(([^\\s()<>]+| \\\n",
    "        (\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:\\'\".,<>?¬´¬ª‚Äú‚Äù‚Äò‚Äô]))','', noEmail)\n",
    "\n",
    "    # 3. Remove Emojis\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                                   u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                                   u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                                   u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                                   u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                                   u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                                   u\"\\U00002702-\\U000027B0\"\n",
    "                                   u\"\\U00002702-\\U000027B0\"\n",
    "                                   u\"\\U000024C2-\\U0001F251\"\n",
    "                                   u\"\\U0001f926-\\U0001f937\"\n",
    "                                   u\"\\U00010000-\\U0010ffff\"\n",
    "                                   u\"\\u2640-\\u2642\"\n",
    "                                   u\"\\u2600-\\u2B55\"\n",
    "                                   u\"\\u200d\"\n",
    "                                   u\"\\u23cf\"\n",
    "                                   u\"\\u23e9\"\n",
    "                                   u\"\\u231a\"\n",
    "                                   u\"\\ufe0f\"  # dingbats\n",
    "                                   u\"\\u3030\"\n",
    "                                   \"]+\", flags=re.UNICODE)\n",
    "    noEmoji = emoji_pattern.sub(r'', noEmail)\n",
    "\n",
    "#     noEmoji = re.sub(emoji.get_emoji_regexp(), r\"\", noEmail) \n",
    "    \n",
    "    return noEmoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"commentText\"] = train_data[\"commentText\"].apply(pre_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[\"commentText\"] = test_data[\"commentText\"].apply(pre_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train_data[[\"label\"]]\n",
    "train_data_1 = train_data.drop(\"label\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Processing</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inltk.inltk import tokenize\n",
    "from indicnlp.tokenize import indic_tokenize\n",
    "from inltk.inltk import identify_language\n",
    "\n",
    "def get_tokens(string, language):\n",
    "    try:\n",
    "        if language == \"Hindi\":\n",
    "                if identify_language(string) == \"hi\":\n",
    "                    return tokenize(string, \"hi\")\n",
    "                else:\n",
    "                    return tokenize(string, \"hi-en\")\n",
    "        elif language == \"Telugu\":\n",
    "            return tokenize(string, \"te\")\n",
    "        elif language == \"Marathi\":\n",
    "            return tokenize(string, \"mr\")\n",
    "        elif language == \"Tamil\":\n",
    "            return tokenize(string, \"ta\")\n",
    "        elif language == \"Malayalam\":\n",
    "            return tokenize(string, \"ml\")\n",
    "        elif language == \"Bengali\":\n",
    "            return tokenize(string, \"bn\")\n",
    "        elif language == \"Kannada\":\n",
    "            return tokenize(string, \"kn\")\n",
    "        elif language == \"Odia\":\n",
    "            return tokenize(string, \"or\")\n",
    "        elif language == \"Gujarati\":\n",
    "            return tokenize(string, \"gu\")\n",
    "        else:\n",
    "            return indic_tokenize.trivial_tokenize(string)\n",
    "    except:\n",
    "        return indic_tokenize.trivial_tokenize(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from indicnlp.tokenize import indic_tokenize\n",
    "\n",
    "def tokenize(string):\n",
    "    return indic_tokenize.trivial_tokenize(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"commentText\"] = train_data[\"commentText\"].apply(tokenize)\n",
    "test_data[\"commentText\"] = test_data[\"commentText\"].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.clock()\n",
    "train_data['commentText'] = train_data.apply(lambda x: get_tokens(x.commentText, x.language), axis=1)\n",
    "end_time = time.clock()\n",
    "\n",
    "print(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['commentText'] = test_data.apply(lambda x: get_tokens(x.commentText, x.language), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "train_data[\"commentText\"] = train_data[\"commentText\"].apply(lambda x: re.sub(\"‚ñÅ\", \"\",x))\n",
    "test_data[\"commentText\"] = test_data[\"commentText\"].apply(lambda x: re.sub(\"‚ñÅ\", \"\",x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza\n",
    "\n",
    "nlp_stanza = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma')\n",
    "# train_data[\"commentText\"] = train_data[\"commentText\"].apply(lambda x: nlp_stanza(x))\n",
    "# test_data[\"commentText\"] = test_data[\"commentText\"].apply(lambda x: nlp_stanza(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def create_vector(train_data, test_data): \n",
    "    tfidf_vectorizer = TfidfVectorizer(norm = 'l2', lowercase = False, min_df = 0, stop_words='english',\n",
    "                                       use_idf = True, smooth_idf = False, sublinear_tf = True, \\\n",
    "                                       ngram_range=(1,2))\n",
    "    train_vector = tfidf_vectorizer.fit_transform(train_data)\n",
    "\n",
    "    test_vector = tfidf_vectorizer.transform(test_data)\n",
    "    \n",
    "    return train_vector, test_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"commentText\"] = train_data[\"commentText\"].apply(lambda x: \" \".join(x))\n",
    "test_data[\"commentText\"] = test_data[\"commentText\"].apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import new libraries\n",
    "import matplotlib.pyplot as mtp\n",
    "%matplotlib inline\n",
    "import wordcloud\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "# Create a wordcloud of the movie genre\n",
    "title_corpus = ' '.join(train_data[\"commentText\"])\n",
    "title_wordcloud = WordCloud(stopwords=STOPWORDS, background_color='black', height=2000, width=4000).generate(title_corpus)\n",
    "\n",
    "# Plot the wordcloud\n",
    "mtp.figure(figsize=(16,8))\n",
    "mtp.imshow(title_wordcloud)\n",
    "mtp.axis('off')\n",
    "mtp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vector, test_vector = create_vector(train_data[\"commentText\"], test_data[\"commentText\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Logistic Regression</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# logreg = LogisticRegression(solver='lbfgs',class_weight='balanced', max_iter=10000)\n",
    "logreg = LogisticRegression(C=2, dual=False, solver='liblinear', max_iter=10000)\n",
    "logreg.fit(train_vector, train_data[\"label\"])\n",
    "y_pred = logreg.predict(test_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_file(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(solver='lbfgs',class_weight='balanced', max_iter=10000)\n",
    "\n",
    "Cross_Validation(10, model, train_vector, train_data[\"label\"] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Random Forest Classifier</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(train_vector, train_data[\"label\"])\n",
    "y_pred = rfc.predict(test_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_file(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>K-Nearest Neighbor</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(train_vector, train_data[\"label\"])\n",
    "y_pred = knn.predict(test_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_file(y_pred) #submission4.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Grid Search CV</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "forest_params = [{'max_depth': list(range(10, 15)), 'max_features': list(range(0,14))}]\n",
    "clf = GridSearchCV(rfc, forest_params, cv = 10, scoring='accuracy')\n",
    "\n",
    "clf.fit(train_vector, train_data[\"label\"])\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Cross Validation Method</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation (Tested Features)\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def Cross_Validation(n_splits, model, X, y ):\n",
    "    cv = KFold(n_splits=n_splits, random_state=1, shuffle=True)\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv)\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "# cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "# model = LogisticRegression(solver='lbfgs',class_weight='balanced', max_iter=10000)\n",
    "# scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(_train_data, train_labels, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Saving to file</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method to write to file\n",
    "import csv \n",
    "\n",
    "def write_to_file(predictions):\n",
    "   \n",
    "    # field names \n",
    "    fields = ['Id', 'Expected'] \n",
    "\n",
    "    # data rows of csv file \n",
    "    rows = []\n",
    "    for index, value in enumerate(predictions):\n",
    "        rows.append([index+2, value])\n",
    "\n",
    "    # name of csv file \n",
    "    filename = \"/Users/krishna/workspace/python/CS584/Multilingual_Abusive_Comment_Identification/submission7.csv\"\n",
    "\n",
    "    # writing to csv file \n",
    "    with open(filename, 'w') as csvfile: \n",
    "        # creating a csv writer object \n",
    "        csvwriter = csv.writer(csvfile) \n",
    "\n",
    "        # writing the fields \n",
    "        csvwriter.writerow(fields) \n",
    "\n",
    "        # writing the data rows \n",
    "        csvwriter.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data[train_data[\"language\"]==\"Hindi\"].iloc[0][\"commentText\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_labels = train_data.label\n",
    "# # train_data = train_data.iloc[:,1:-2]\n",
    "# _train_data = train_data.commentText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from emot.emo_unicode import EMOTICONS_EMO\n",
    "# import emoji\n",
    "\n",
    "# def strip_emoji(string):\n",
    "#     return re.sub(emoji.get_emoji_regexp(), r\"\", string)\n",
    "# def remove_emoji(string):\n",
    "#     emoji_pattern = re.compile(\"[\"\n",
    "#                            u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "#                            u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "#                            u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "#                            u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "#                            u\"\\U00002702-\\U000027B0\"\n",
    "#                            u\"\\U000024C2-\\U0001F251\"\n",
    "#                            \"]+\", flags=re.UNICODE)\n",
    "#     return emoji_pattern.sub(r'', string)\n",
    "\n",
    "# def remove_emoticons(text):\n",
    "#     emoticon_pattern = re.compile(u'(' + u'|'.join(k for k in EMOTICONS_EMO) + u')')\n",
    "#     return emoticon_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from inltk.inltk import get_embedding_vectors\n",
    "\n",
    "# # get embedding for input words\n",
    "# vectors = get_embedding_vectors(\"‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§ø‡§ï‡•Ä ‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ\", \"hi\")\n",
    "\n",
    "# print(vectors)\n",
    "# # print shape of the first word\n",
    "# print(\"shape:\", vectors[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Langugae Detection ###\n",
    "\n",
    "# from textblob import TextBlob\n",
    "\n",
    "# lang = TextBlob(\"Free fire pubg ka baap ha kutta sala kamina\") \n",
    "# print(lang.detect_language())\n",
    "\n",
    "\n",
    "# from langdetect import detect\n",
    "\n",
    "# detect(\"Saale Tu kon sa pagal Nahi h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Transliterate ###\n",
    "\n",
    "from indicnlp.transliterate.unicode_transliterate import UnicodeIndicTransliterator\n",
    "input_text = \"Free fire pubg ka baap ha kutta sala kamina\"\n",
    "print(UnicodeIndicTransliterator.transliterate(input_text,\"hi\",\"hi\"))\n",
    "\n",
    "\n",
    "from indic_transliteration import sanscript\n",
    "from indic_transliteration.sanscript import transliterate\n",
    "y = \"Free fire pubg ka baap ha kutta sala kamina\"\n",
    "print(transliterate(y, sanscript.ITRANS, sanscript.DEVANAGARI))\n",
    "\n",
    "from indicnlp.transliterate.unicode_transliterate import UnicodeIndicTransliterator\n",
    "from indicnlp.transliterate.acronym_transliterator import LatinToIndicAcronymTransliterator\n",
    "x = \"‡§∂‡§æ‡§Ø‡§¶ ‡§Ø‡•ã‡§ó‡•Ä ‡§ú‡•Ä ‡§π‡•à\"\n",
    "print(UnicodeIndicTransliterator.transliterate(x,\"hi\",\"eng\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tokenize ###\n",
    "\n",
    "from indicnlp.tokenize import indic_tokenize\n",
    "hindi_text = \"Free fire pubg ka baap ha kutta sala kamina\"\n",
    "print(indic_tokenize.trivial_tokenize(hindi_text))\n",
    "\n",
    "\n",
    "# from textblob import TextBlob\n",
    "# from inltk.inltk import tokenize\n",
    "\n",
    "# def get_tokens(string, language):\n",
    "#     if language == \"Hindi\":\n",
    "#         tokens = tokenize(string, \"hi\")\n",
    "#         return tokens\n",
    "\n",
    "from inltk.inltk import tokenize\n",
    "\n",
    "hindi_text = \"\"\"‡§™‡•ç‡§∞‡§æ‡§ö‡•Ä‡§® ‡§ï‡§æ‡§≤ ‡§Æ‡•á‡§Ç ‡§µ‡§ø‡§ï‡•ç‡§∞‡§Æ‡§æ‡§¶‡§ø‡§§‡•ç‡§Ø ‡§®‡§æ‡§Æ ‡§ï‡•á ‡§è‡§ï ‡§Ü‡§¶‡§∞‡•ç‡§∂ ‡§∞‡§æ‡§ú‡§æ ‡§π‡•Å‡§Ü ‡§ï‡§∞‡§§‡•á ‡§•‡•á‡•§\n",
    "‡§Ö‡§™‡§®‡•á ‡§∏‡§æ‡§π‡§∏, ‡§™‡§∞‡§æ‡§ï‡•ç‡§∞‡§Æ ‡§î‡§∞ ‡§∂‡•å‡§∞‡•ç‡§Ø ‡§ï‡•á ‡§≤‡§ø‡§è  ‡§∞‡§æ‡§ú‡§æ ‡§µ‡§ø‡§ï‡•ç‡§∞‡§Æ ‡§Æ‡§∂‡§π‡•Ç‡§∞ ‡§•‡•á‡•§ \n",
    "‡§ê‡§∏‡§æ ‡§≠‡•Ä ‡§ï‡§π‡§æ ‡§ú‡§æ‡§§‡§æ ‡§π‡•à ‡§ï‡§ø ‡§∞‡§æ‡§ú‡§æ ‡§µ‡§ø‡§ï‡•ç‡§∞‡§Æ ‡§Ö‡§™‡§®‡•Ä ‡§™‡•ç‡§∞‡§æ‡§ú‡§æ ‡§ï‡•á ‡§ú‡•Ä‡§µ‡§® ‡§ï‡•á ‡§¶‡•Å‡§ñ ‡§¶‡§∞‡•ç‡§¶ ‡§ú‡§æ‡§®‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∞‡§æ‡§§‡•ç‡§∞‡•Ä ‡§ï‡•á ‡§™‡§π‡§∞ ‡§Æ‡•á‡§Ç ‡§≠‡•á‡§∑ ‡§¨‡§¶‡§≤ ‡§ï‡§∞ ‡§®‡§ó‡§∞ ‡§Æ‡•á‡§Ç ‡§ò‡•Ç‡§Æ‡§§‡•á ‡§•‡•á‡•§\"\"\"\n",
    "\n",
    "hindi_text = \"‡§´‡•ç‡§∞‡•Ä ‡§´‡§æ‡§Ø‡§∞ ‡§™‡§¨ ‡§ï‡§æ ‡§¨‡§æ‡§™ ‡§π‡§æ ‡§ï‡•Å‡§ü‡•ç‡§ü‡§æ ‡§∏‡§æ‡§≤‡§æ ‡§ï‡§Æ‡•Ä‡§®‡§æ\"\n",
    "\n",
    "# tokenize(input text, language code)\n",
    "tokenize(hindi_text, \"hi\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Venv DM",
   "language": "python",
   "name": "venv_dm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
